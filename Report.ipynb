{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the second project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.WARN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Reacher.app\"`\n",
    "- **Windows** (x86): `\"path/to/Reacher_Windows_x86/Reacher.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Reacher_Windows_x86_64/Reacher.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Reacher_Linux/Reacher.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Reacher_Linux/Reacher.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Reacher.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Reacher.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = UnityEnvironment(file_name='Reacher.app')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, a double-jointed arm can move to target locations. A reward of `+0.1` is provided for each step that the agent's hand is in the goal location. Thus, the goal of your agent is to maintain its position at the target location for as many time steps as possible.\n",
    "\n",
    "The observation space consists of `33` variables corresponding to position, rotation, velocity, and angular velocities of the arm.  Each action is a vector with four numbers, corresponding to torque applicable to two joints.  Every entry in the action vector must be a number between `-1` and `1`.\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Approach\n",
    "\n",
    "I took my earlier implementation on the __[navigation task](https://github.com/dahlem/deep-reinforcement-learning-navigation)__ and modularized the DDPG RL agent and actor/critic implementations. Both, the actor and critic can be configured to use LayerNorms in order to speed up learning with a larger learning rate. I introduced common random number generators to give each stochastic components its own seed to ensure that each component is decoupled. I used www.random.org to serialize 1000 seeds into a file, which is relayed through a seeds generator API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Experiments\n",
    "\n",
    "In the following sections I am going to present a serious of experiments that lead me to solve this environment. I had a few earlier attempts that performed poorly which I did not include. While I implemented a parallel agent environment, I did not complete a run. The following experiments are conducted on the single-agent environments but the number of udpate rounds is configurable and it works in conjunction with the configuration parameter to learn at every n-th step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 First Experiment\n",
    "\n",
    "The first experiment uses a uniform replay buffer and actor/critic architectures with 256/256/64 neurons per layer each. The actor action values are fed into the critic in the second layer (which is also a configuration parameter. Noise is added and weight decay is applied to the critic.\n",
    "\n",
    "This experiment did not result in any learned skill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from rl.ddpg_agent import DDPGAgent\n",
    "from rl.train import train\n",
    "from utils.rnd import Seeds\n",
    "\n",
    "seedGenerator = Seeds('seeds')\n",
    "seedGenerator.next()\n",
    "from rl.buffer import UniformReplayBuffer\n",
    "\n",
    "\n",
    "experience_params = {\n",
    "    'seed': seedGenerator,       # seed for the experience replay buffer\n",
    "    'buffer_size': 100000,        # size of the replay buffer\n",
    "    'batch_size': 128            # batch size sampled from the replay buffer\n",
    "}\n",
    "\n",
    "experienceReplay = UniformReplayBuffer(experience_params)\n",
    "\n",
    "params = {\n",
    "    'name': 'DDPG-1',\n",
    "    'episodes': 2000,            # number of episodes\n",
    "    'maxlen': 100,               # sliding window size of recent scores\n",
    "    'brain_name': brain_name,    # the brain name of the unity environment\n",
    "    'achievement': 30.,           # score at which the environment is considered solved\n",
    "    'environment': env,\n",
    "    'agent_params': {\n",
    "        'experience_replay': experienceReplay,\n",
    "        'seed': seedGenerator,\n",
    "        'num_agents': num_agents,    # number of agents in the environment\n",
    "        'gamma': 0.99,               # discount factor\n",
    "        'tau': 0.001,                # mixing rate soft-update of target parameters\n",
    "        'update_every': 10,        # update every n-th step\n",
    "        'num_updates': 5,            # we don't necessarily need to run as many rounds of updates as there are agents\n",
    "        'add_noise': True,          # add noise using 'noise_params'\n",
    "        'actor_params': {            # actor parameters\n",
    "            'norm': False,\n",
    "            'lr': 0.001,            # learning rate\n",
    "            'state_size': state_size,    # size of the state space\n",
    "            'action_size': action_size,  # size of the action space\n",
    "            'seed': seedGenerator,                # seed of the network architecture\n",
    "            'hidden_layers': [256, 256, 64], # hidden layer neurons\n",
    "            'dropout': 0.05,\n",
    "            'act_fn': [F.leaky_relu, F.leaky_relu, F.tanh]\n",
    "        },\n",
    "        'critic_params': {               # critic parameters\n",
    "            'norm': False,\n",
    "            'lr': 0.001,                 # learning rate\n",
    "            'weight_decay': 0.001,          # weight decay\n",
    "            'state_size': state_size,    # size of the state space\n",
    "            'action_size': action_size,  # size of the action space\n",
    "            'seed': seedGenerator,               # seed of the network architecture\n",
    "            'hidden_layers': [256, 256, 64], # hidden layer neurons\n",
    "            'dropout': 0.05,\n",
    "            'action_layer': 1,\n",
    "            'act_fn': [F.leaky_relu, F.leaky_relu, lambda x: x]\n",
    "        },\n",
    "        'noise_params': {            # parameters for the noisy process\n",
    "            'mu': 0.,                # mean\n",
    "            'theta': 0.15,           # theta value for the ornstein-uhlenbeck process\n",
    "            'sigma': 0.2,            # variance\n",
    "            'seed': seedGenerator,         # seed\n",
    "            'action_size': action_size\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "agents = [DDPGAgent(idx=idx, params=params['agent_params']) for idx, a in enumerate(range(num_agents))]\n",
    "\n",
    "scores = train(agents=agents, params=params)\n",
    "\n",
    "df = pd.DataFrame(data={'episode': np.arange(len(scores)), 'DDPG-1': scores})\n",
    "df.to_csv('results/DDPG-1-scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Second Experiments\n",
    "\n",
    "The second experiment uses the same architecture but introduces normalising layers between the linear layers and the activation functions. Since we are using normalising layers we do not apply weight decay to the critic.\n",
    "\n",
    "While this experiment did not solve the environment, it did result in a significant improvement over the previous experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from rl.ddpg_agent import DDPGAgent\n",
    "from rl.train import train\n",
    "from utils.rnd import Seeds\n",
    "\n",
    "seedGenerator = Seeds('seeds')\n",
    "seedGenerator.next()\n",
    "from rl.buffer import UniformReplayBuffer\n",
    "\n",
    "\n",
    "experience_params = {\n",
    "    'seed': seedGenerator,       # seed for the experience replay buffer\n",
    "    'buffer_size': 100000,        # size of the replay buffer\n",
    "    'batch_size': 128            # batch size sampled from the replay buffer\n",
    "}\n",
    "\n",
    "experienceReplay = UniformReplayBuffer(experience_params)\n",
    "\n",
    "params = {\n",
    "    'name': 'DDPG-2',\n",
    "    'episodes': 2000,            # number of episodes\n",
    "    'maxlen': 100,               # sliding window size of recent scores\n",
    "    'brain_name': brain_name,    # the brain name of the unity environment\n",
    "    'achievement': 30.,           # score at which the environment is considered solved\n",
    "    'environment': env,\n",
    "    'agent_params': {\n",
    "        'experience_replay': experienceReplay,\n",
    "        'seed': seedGenerator,\n",
    "        'num_agents': num_agents,    # number of agents in the environment\n",
    "        'gamma': 0.99,               # discount factor\n",
    "        'tau': 0.001,                # mixing rate soft-update of target parameters\n",
    "        'update_every': 10,        # update every n-th step\n",
    "        'num_updates': 5,            # we don't necessarily need to run as many rounds of updates as there are agents\n",
    "        'add_noise': True,          # add noise using 'noise_params'\n",
    "        'actor_params': {            # actor parameters\n",
    "            'norm': True,\n",
    "            'lr': 0.001,            # learning rate\n",
    "            'state_size': state_size,    # size of the state space\n",
    "            'action_size': action_size,  # size of the action space\n",
    "            'seed': seedGenerator,                # seed of the network architecture\n",
    "            'hidden_layers': [256, 256, 64], # hidden layer neurons\n",
    "            'dropout': 0.05,\n",
    "            'act_fn': [F.leaky_relu, F.leaky_relu, F.tanh]\n",
    "        },\n",
    "        'critic_params': {               # critic parameters\n",
    "            'norm': True,\n",
    "            'lr': 0.001,                 # learning rate\n",
    "            'weight_decay': 0.0,          # weight decay\n",
    "            'state_size': state_size,    # size of the state space\n",
    "            'action_size': action_size,  # size of the action space\n",
    "            'seed': seedGenerator,               # seed of the network architecture\n",
    "            'hidden_layers': [256, 256, 64], # hidden layer neurons\n",
    "            'dropout': 0.05,\n",
    "            'action_layer': 1,\n",
    "            'act_fn': [F.leaky_relu, F.leaky_relu, lambda x: x]\n",
    "        },\n",
    "        'noise_params': {            # parameters for the noisy process\n",
    "            'mu': 0.,                # mean\n",
    "            'theta': 0.15,           # theta value for the ornstein-uhlenbeck process\n",
    "            'sigma': 0.2,            # variance\n",
    "            'seed': seedGenerator,         # seed\n",
    "            'action_size': action_size\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "agents = [DDPGAgent(idx=idx, params=params['agent_params']) for idx, a in enumerate(range(num_agents))]\n",
    "\n",
    "scores = train(agents=agents, params=params)\n",
    "\n",
    "df = pd.DataFrame(data={'episode': np.arange(len(scores)), 'DDPG-2': scores})\n",
    "df.to_csv('results/DDPG-2-scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Third Experiment\n",
    "\n",
    "The third experiment builds on the previous one and increases the neurons in the fully connected layers from 256/256/64 to 512/512/128 neurons.\n",
    "\n",
    "This experiment was solved in 465 episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from rl.ddpg_agent import DDPGAgent\n",
    "from rl.train import train\n",
    "from utils.rnd import Seeds\n",
    "\n",
    "seedGenerator = Seeds('seeds')\n",
    "seedGenerator.next()\n",
    "from rl.buffer import UniformReplayBuffer\n",
    "\n",
    "\n",
    "experience_params = {\n",
    "    'seed': seedGenerator,       # seed for the experience replay buffer\n",
    "    'buffer_size': 100000,        # size of the replay buffer\n",
    "    'batch_size': 128            # batch size sampled from the replay buffer\n",
    "}\n",
    "\n",
    "experienceReplay = UniformReplayBuffer(experience_params)\n",
    "\n",
    "params = {\n",
    "    'name': 'DDPG-3',\n",
    "    'episodes': 2000,            # number of episodes\n",
    "    'maxlen': 100,               # sliding window size of recent scores\n",
    "    'brain_name': brain_name,    # the brain name of the unity environment\n",
    "    'achievement': 30.,           # score at which the environment is considered solved\n",
    "    'environment': env,\n",
    "    'agent_params': {\n",
    "        'experience_replay': experienceReplay,\n",
    "        'seed': seedGenerator,\n",
    "        'num_agents': num_agents,    # number of agents in the environment\n",
    "        'gamma': 0.99,               # discount factor\n",
    "        'tau': 0.001,                # mixing rate soft-update of target parameters\n",
    "        'update_every': 10,        # update every n-th step\n",
    "        'num_updates': 5,            # we don't necessarily need to run as many rounds of updates as there are agents\n",
    "        'add_noise': True,          # add noise using 'noise_params'\n",
    "        'actor_params': {            # actor parameters\n",
    "            'norm': True,\n",
    "            'lr': 0.001,            # learning rate\n",
    "            'state_size': state_size,    # size of the state space\n",
    "            'action_size': action_size,  # size of the action space\n",
    "            'seed': seedGenerator,                # seed of the network architecture\n",
    "            'hidden_layers': [512, 512, 128], # hidden layer neurons\n",
    "            'dropout': 0.05,\n",
    "            'act_fn': [F.leaky_relu, F.leaky_relu, F.tanh]\n",
    "        },\n",
    "        'critic_params': {               # critic parameters\n",
    "            'norm': True,\n",
    "            'lr': 0.001,                 # learning rate\n",
    "            'weight_decay': 0.0,          # weight decay\n",
    "            'state_size': state_size,    # size of the state space\n",
    "            'action_size': action_size,  # size of the action space\n",
    "            'seed': seedGenerator,               # seed of the network architecture\n",
    "            'hidden_layers': [512, 512, 128], # hidden layer neurons\n",
    "            'dropout': 0.05,\n",
    "            'action_layer': 1,\n",
    "            'act_fn': [F.leaky_relu, F.leaky_relu, lambda x: x]\n",
    "        },\n",
    "        'noise_params': {            # parameters for the noisy process\n",
    "            'mu': 0.,                # mean\n",
    "            'theta': 0.15,           # theta value for the ornstein-uhlenbeck process\n",
    "            'sigma': 0.2,            # variance\n",
    "            'seed': seedGenerator,         # seed\n",
    "            'action_size': action_size\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "agents = [DDPGAgent(idx=idx, params=params['agent_params']) for idx, a in enumerate(range(num_agents))]\n",
    "\n",
    "scores = train(agents=agents, params=params)\n",
    "\n",
    "df = pd.DataFrame(data={'episode': np.arange(len(scores)), 'DDPG-3': scores})\n",
    "df.to_csv('results/DDPG-3-scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Here we summarize the results and show the learning curves over 2000 episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x118bea400>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "achievementWindow = 100\n",
    "df = pd.concat([pd.read_csv(f) for f in glob.glob('results/*-scores.csv')], axis=1)\n",
    "df = df.loc[:,~df.columns.duplicated()]\n",
    "\n",
    "dfRolling = df.rolling(achievementWindow).mean()\n",
    "dfRolling.plot(x='episode', y=['DDPG-1', 'DDPG-2', 'DDPG-3'], kind='line')\n",
    "solvedAt = dfRolling[dfRolling['DDPG-3']>=30.0].index[0] - achievementWindow\n",
    "plt.axvline(x=solvedAt, color='red')\n",
    "plt.axhline(y=30, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
